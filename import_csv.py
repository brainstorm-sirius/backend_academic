"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ CSV —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python import_csv.py
"""
import csv
import os
from pathlib import Path
from sqlalchemy.orm import Session
from app.database import SessionLocal, engine
from app.models import Base, Author, AuthorInterest

# –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ –∏—Ö –µ—â—ë –Ω–µ—Ç
Base.metadata.create_all(bind=engine)


def import_authors_csv(db: Session, csv_path: str, batch_size: int = 1000):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç authors_expanded_with_ids.csv –≤ —Ç–∞–±–ª–∏—Ü—É authors"""
    print(f"–ù–∞—á–∏–Ω–∞—é –∏–º–ø–æ—Ä—Ç {csv_path}...")
    
    count = 0
    batch = []
    
    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            author = Author(
                pmid=row.get('PMID') or None,
                title=row.get('Title') or None,
                authors_original=row.get('Authors_Original') or None,
                citation=row.get('Citation') or None,
                journal_book=row.get('Journal/Book') or None,
                publication_year=row.get('Publication Year') or None,
                create_date=row.get('Create Date') or None,
                pmcid=row.get('PMCID') or None,
                nihms_id=row.get('NIHMS ID') or None,
                doi=row.get('DOI') or None,
                author_name=row.get('Author_Name') or None,
                author_id=row.get('Author_ID') or None,
            )
            batch.append(author)
            count += 1
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if len(batch) >= batch_size:
                db.bulk_save_objects(batch)
                db.commit()
                batch = []
                print(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π...")
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø–∏—Å–∏
    if batch:
        db.bulk_save_objects(batch)
        db.commit()
    
    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω! –í—Å–µ–≥–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –∞–≤—Ç–æ—Ä–æ–≤.")


def import_interests_csv(db: Session, csv_path: str, batch_size: int = 1000):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç authors_scientific_interests.csv –≤ —Ç–∞–±–ª–∏—Ü—É author_interests"""
    print(f"–ù–∞—á–∏–Ω–∞—é –∏–º–ø–æ—Ä—Ç {csv_path}...")
    
    count = 0
    skipped = 0
    duplicates = 0
    batch = []
    row_num = 0
    
    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            row_num += 1
            
            # –ü–æ–ª—É—á–∞–µ–º author_id –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–Ω –Ω–µ –ø—É—Å—Ç–æ–π
            author_id = row.get('Author_ID', '').strip() if row.get('Author_ID') else ''
            
            # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ –¥–ª—è –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–æ–∫
            if row_num <= 3:
                print(f"–û—Ç–ª–∞–¥–∫–∞ —Å—Ç—Ä–æ–∫–∞ {row_num}: Author_ID = '{author_id}' (—Ç–∏–ø: {type(author_id)}, –¥–ª–∏–Ω–∞: {len(author_id)})")
                print(f"  –í—Å–µ –∫–ª—é—á–∏ –≤ row: {list(row.keys())}")
                print(f"  –ó–Ω–∞—á–µ–Ω–∏–µ row.get('Author_ID'): '{row.get('Author_ID')}'")
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ author_id (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ)
            if not author_id:
                skipped += 1
                if skipped <= 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö
                    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {row_num}: –ø—É—Å—Ç–æ–π Author_ID")
                continue
            
            interest = AuthorInterest(
                author_id=author_id,
                author_name=row.get('Author_Name') or None,
                interests_list=row.get('Interests_List') or None,
                keywords_list=row.get('Keywords_List') or None,
                interests_count=int(row['Interests_Count']) if row.get('Interests_Count') and str(row['Interests_Count']).strip().isdigit() else None,
                articles_count=int(row['Articles_Count']) if row.get('Articles_Count') and str(row['Articles_Count']).strip().isdigit() else None,
                main_interest=row.get('Main_Interest') or None,
                cluster=int(row['Cluster']) if row.get('Cluster') and str(row['Cluster']).strip().isdigit() else None,
            )
            batch.append(interest)
            count += 1
            
            # –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if len(batch) >= batch_size:
                try:
                    db.bulk_save_objects(batch)
                    db.commit()
                    batch = []
                    print(f"–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π... (–ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ {duplicates})")
                except Exception as e:
                    db.rollback()
                    # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏, –ø—Ä–æ–±—É–µ–º –≤—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ –æ–¥–Ω–æ–π
                    if "UNIQUE constraint" in str(e) or "IntegrityError" in str(type(e).__name__):
                        print(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –≤—Å—Ç–∞–≤–∫—É...")
                        for item in batch:
                            try:
                                db.add(item)
                                db.commit()
                            except Exception as dup_error:
                                db.rollback()
                                if "UNIQUE constraint" in str(dup_error) or "IntegrityError" in str(type(dup_error).__name__):
                                    duplicates += 1
                                    count -= 1
                                else:
                                    raise
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ: {e}")
                        raise
                    batch = []
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø–∏—Å–∏
    if batch:
        try:
            db.bulk_save_objects(batch)
            db.commit()
        except Exception as e:
            db.rollback()
            if "UNIQUE constraint" in str(e) or "IntegrityError" in str(type(e).__name__):
                # –ü–æ—à—Ç—É—á–Ω–∞—è –≤—Å—Ç–∞–≤–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è
                for item in batch:
                    try:
                        db.add(item)
                        db.commit()
                    except Exception as dup_error:
                        db.rollback()
                        if "UNIQUE constraint" in str(dup_error) or "IntegrityError" in str(type(dup_error).__name__):
                            duplicates += 1
                            count -= 1
                        else:
                            raise
            else:
                raise
    
    print(f"‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω! –í—Å–µ–≥–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –Ω–∞—É—á–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤.")
    if skipped > 0:
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ {skipped} –∑–∞–ø–∏—Å–µ–π –±–µ–∑ Author_ID.")
    if duplicates > 0:
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (author_id —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç).")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–º–ø–æ—Ä—Ç–∞"""
    db = SessionLocal()
    
    try:
        # –ü—É—Ç–∏ –∫ CSV —Ñ–∞–π–ª–∞–º
        base_dir = Path(__file__).parent
        authors_csv = base_dir / "authors_expanded_with_ids.csv"
        interests_csv = base_dir / "authors_scientific_interests.csv"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
        if not authors_csv.exists():
            print(f"‚ùå –§–∞–π–ª {authors_csv} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
        
        if not interests_csv.exists():
            print(f"‚ùå –§–∞–π–ª {interests_csv} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
        
        print("=" * 60)
        print("–ù–∞—á–∏–Ω–∞—é –∏–º–ø–æ—Ä—Ç CSV —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        print("=" * 60)
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≤—Ç–æ—Ä–æ–≤
        print("\nüìö –ò–º–ø–æ—Ä—Ç –∞–≤—Ç–æ—Ä–æ–≤ –∏ —Å—Ç–∞—Ç–µ–π...")
        # import_authors_csv(db, str(authors_csv))
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—É—á–Ω—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã
        print("\nüî¨ –ò–º–ø–æ—Ä—Ç –Ω–∞—É—á–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤...")
        import_interests_csv(db, str(interests_csv))
        
        print("\n" + "=" * 60)
        print("‚úÖ –ò–º–ø–æ—Ä—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ: {e}")
        db.rollback()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    main()

